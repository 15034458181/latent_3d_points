{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook will help you train a latent Point-Cloud GAN.\n",
    "\n",
    "(Assumes latent_3d_points is in the PYTHONPATH and that a trained AE model exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os.path as osp\n",
    "\n",
    "from latent_3d_points.src.autoencoder import Configuration as Conf\n",
    "from latent_3d_points.src.point_net_ae import PointNetAutoEncoder\n",
    "\n",
    "from latent_3d_points.src.in_out import snc_category_to_synth_id, create_dir, PointCloudDataSet, \\\n",
    "                                        load_all_point_clouds_under_folder\n",
    "\n",
    "from latent_3d_points.src.tf_utils import reset_tf_graph\n",
    "\n",
    "from latent_3d_points.src.vanilla_gan import Vanilla_GAN\n",
    "from latent_3d_points.src.w_gan_gp import W_GAN_GP\n",
    "\n",
    "from latent_3d_points.src.generators_discriminators import latent_code_discriminator_two_layers,\\\n",
    "latent_code_generator_two_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me the class name (e.g. \"chair\"): chair\n"
     ]
    }
   ],
   "source": [
    "# Set DATA/AE parameters\n",
    "\n",
    "top_out_dir = '../data/'                                       # Use to save Neural-Net check-points etc.\n",
    "top_in_dir = '../data/shape_net_core_uniform_samples_2048/'    # Top-dir of where point-clouds are stored.\n",
    "\n",
    "ae_configuration = '../data/single_class_ae/configuration'     # AE model-description. You can alternatively, \n",
    "                                                               # use your own way to load a pre-trained AE.\n",
    "\n",
    "ae_epoch = 100                                                 # Model/epoch of AE to load.\n",
    "bneck_size = 128                                               # Bottleneck-AE size\n",
    "\n",
    "experiment_name = 'latent_gan'\n",
    "n_pc_points = 2048                                             # Number of points per model.\n",
    "\n",
    "class_name = raw_input('Give me the class name (e.g. \"chair\"): ').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set GAN, training parameters.\n",
    "\n",
    "# save_model = False\n",
    "# class_name = raw_input('Give me the class type.\\n').lower()\n",
    "# syn_id = snc_category_to_synth_id()[class_name]\n",
    "# ae_loss = 'emd'\n",
    "use_wgan = False\n",
    "max_epochs = 500\n",
    "plot_train_curve = True\n",
    "saver_step = np.hstack([np.array([1, 5, 10]), np.arange(50, max_epochs+1, 50)])\n",
    "save_synthetic_samples = True\n",
    "experiment_tag = 'test'\n",
    "\n",
    "init_lr = 0.0001\n",
    "batch_size = 50\n",
    "noise_params = {'mu':0, 'sigma': 0.2}\n",
    "noise_dim = bneck_size\n",
    "beta = 0.5\n",
    "n_syn_samples = train_data.num_examples  # How many samples to produce in each save step.\n",
    "n_out = [bneck_size]\n",
    "accum_syn_data = []\n",
    "train_stats = []\n",
    "\n",
    "if save_synthetic_samples:\n",
    "    synthetic_data_out_dir = osp.join(top_out_dir, 'OUT/synthetic_samples/', experiment_tag)\n",
    "    create_dir(synthetic_data_out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6778 pclouds were loaded. They belong in 1 shape-classes.\n"
     ]
    }
   ],
   "source": [
    "# Load point-clouds\n",
    "syn_id = snc_category_to_synth_id()[class_name]\n",
    "class_dir = osp.join(top_in_dir , syn_id)\n",
    "all_pc_data = load_all_point_clouds_under_folder(class_dir, n_threads=8, file_ending='.ply', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Encoder\n",
      "encoder_conv_layer_0 conv params =  256 bnorm params =  128\n",
      "Tensor(\"single_class_ae_2/Relu:0\", shape=(?, 2048, 64), dtype=float32)\n",
      "output size: 131072 \n",
      "\n",
      "encoder_conv_layer_1 conv params =  8320 bnorm params =  256\n",
      "Tensor(\"single_class_ae_2/Relu_1:0\", shape=(?, 2048, 128), dtype=float32)\n",
      "output size: 262144 \n",
      "\n",
      "encoder_conv_layer_2 conv params =  16512 bnorm params =  256\n",
      "Tensor(\"single_class_ae_2/Relu_2:0\", shape=(?, 2048, 128), dtype=float32)\n",
      "output size: 262144 \n",
      "\n",
      "encoder_conv_layer_3 conv params =  33024 bnorm params =  512\n",
      "Tensor(\"single_class_ae_2/Relu_3:0\", shape=(?, 2048, 256), dtype=float32)\n",
      "output size: 524288 \n",
      "\n",
      "encoder_conv_layer_4 conv params =  32896 bnorm params =  256\n",
      "Tensor(\"single_class_ae_2/Relu_4:0\", shape=(?, 2048, 128), dtype=float32)\n",
      "output size: 262144 \n",
      "\n",
      "Tensor(\"single_class_ae_2/Max:0\", shape=(?, 128), dtype=float32)\n",
      "Building Decoder\n",
      "decoder_fc_0 FC params =  33024 Tensor(\"single_class_ae_2/Relu_5:0\", shape=(?, 256), dtype=float32)\n",
      "output size: 256 \n",
      "\n",
      "decoder_fc_1 FC params =  65792 Tensor(\"single_class_ae_2/Relu_6:0\", shape=(?, 256), dtype=float32)\n",
      "output size: 256 \n",
      "\n",
      "decoder_fc_2 FC params =  1579008 Tensor(\"single_class_ae_2/decoder_fc_2/BiasAdd:0\", shape=(?, 6144), dtype=float32)\n",
      "output size: 6144 \n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ../data/single_class_ae/models.ckpt-100\n",
      "Model restored in epoch 100.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained AE\n",
    "reset_tf_graph()\n",
    "ae_conf = Conf.load(ae_configuration)\n",
    "ae = PointNetAutoEncoder(ae_conf.experiment_name, ae_conf)\n",
    "ae.restore_model(ae_conf.train_dir, ae_epoch, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert raw-data to latent codes.\n",
    "latent_codes = ae.get_latent_codes(all_pc_data.point_clouds)\n",
    "train_data = PointCloudDataSet(latent_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reset_tf_graph()\n",
    "\n",
    "if use_wgan:\n",
    "    lam = 10\n",
    "    gan = W_GAN_GP(experiment_tag, init_lr, lam, n_out, noise_dim, \\\n",
    "                  latent_code_discriminator_two_layers, \n",
    "                  latent_code_generator_two_layers,\\\n",
    "                  beta=beta\n",
    "                 )\n",
    "else:    \n",
    "    gan = Vanilla_GAN(experiment_tag, init_lr, n_out, noise_dim,\n",
    "                     latent_code_discriminator_two_layers, latent_code_generator_two_layers,\n",
    "                     beta=beta\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (0.41234670566475912, 1.9826304430546968)\n",
      "2 (0.092744595168725311, 3.7401423350624414)\n",
      "3 (0.086751907124467523, 4.9079365854677945)\n",
      "4 (0.14127983541592307, 5.5437571193860924)\n",
      "5 (0.11072289509617764, 6.0356144200200621)\n",
      "6 (0.057010742665632913, 6.0249628647514015)\n",
      "7 (0.034189508660979896, 6.2511722398840863)\n",
      "8 (0.02702255496836227, 6.6130070810732633)\n",
      "9 (0.028049864069275236, 6.6683759316154152)\n",
      "10 (0.039642552173008092, 6.2399310899817424)\n",
      "11 (0.067302263495714762, 5.3281164915665338)\n",
      "12 (0.095872920589602506, 4.6584717170051908)\n",
      "13 (0.11670367102260175, 4.179448787025783)\n",
      "14 (0.13206631431113119, 3.9878793301789659)\n",
      "15 (0.16565291175375815, 3.8262052411618441)\n",
      "16 (0.2338887218547904, 3.6161000645678976)\n",
      "17 (0.31642804664114249, 3.3541466132454252)\n",
      "18 (0.4007429537565812, 3.000937961495441)\n",
      "19 (0.50492612304894824, 2.6533821873042895)\n",
      "20 (0.60389162457507595, 2.2986403237218442)\n",
      "21 (0.69011772767357205, 2.038876848635466)\n",
      "22 (0.76728998733603437, 1.8087486132331516)\n",
      "23 (0.84428684193155035, 1.6176354708878891)\n",
      "24 (0.92259861023529721, 1.4711052713186845)\n",
      "25 (0.98413353536439974, 1.3383844899094623)\n",
      "26 (1.058455739332282, 1.2266646571781323)\n",
      "27 (1.0933632700339608, 1.1370870299961255)\n",
      "28 (1.1494868034901826, 1.0696246064227559)\n",
      "29 (1.1742720966753752, 1.0035977975181911)\n",
      "30 (1.1838847149973331, 0.96809209015058439)\n",
      "31 (1.1922432749167733, 0.93998518819394317)\n",
      "32 (1.1877336014872011, 0.92872822388358733)\n",
      "33 (1.1868084233740102, 0.91059028687684429)\n",
      "34 (1.1850983339807262, 0.89915602621824842)\n",
      "35 (1.2114195180975873, 0.89582783813061917)\n",
      "36 (1.2173548066097757, 0.88707890044087945)\n",
      "37 (1.2133679514345916, 0.87999030507129172)\n",
      "38 (1.198970634004344, 0.89574599628863127)\n",
      "39 (1.2071005385854969, 0.88056844680205637)\n",
      "40 (1.2186715789463209, 0.86747113051621805)\n",
      "41 (1.2213859060536261, 0.86541393528813904)\n",
      "42 (1.2314226160878721, 0.85650893190632693)\n",
      "43 (1.2326037386189337, 0.85444202060284824)\n",
      "44 (1.2325126844903698, 0.85386169008586721)\n",
      "45 (1.2365720323894336, 0.84808804626050205)\n",
      "46 (1.2394928206568179, 0.84139824224554971)\n",
      "47 (1.2442763452944547, 0.83001712664313942)\n",
      "48 (1.2364845638689788, 0.8281611535860145)\n",
      "49 (1.2246730410534403, 0.83234623463257496)\n",
      "50 (1.2170278870541116, 0.83547034885572347)\n",
      "51 (1.2177783084952314, 0.83441622049912167)\n",
      "52 (1.2080399171165799, 0.83851466178894041)\n",
      "53 (1.2104164289391559, 0.8362542484117591)\n",
      "54 (1.2086933135986329, 0.84081916446271154)\n",
      "55 (1.2005858390227608, 0.84906800207884414)\n",
      "56 (1.1888435229011205, 0.85882545554119605)\n",
      "57 (1.1837518443231998, 0.8666842486547387)\n",
      "58 (1.1763970292132833, 0.87175706935965491)\n",
      "59 (1.1706018105797145, 0.88083527295485786)\n",
      "60 (1.1620517865471218, 0.89237378732017847)\n",
      "61 (1.1564908359361732, 0.89998021955075469)\n",
      "62 (1.1506333662116008, 0.90722646557766462)\n",
      "63 (1.1477497536203136, 0.91215687212736707)\n",
      "64 (1.1434479029282281, 0.91675022322198618)\n",
      "65 (1.1312506592792013, 0.93126815505649729)\n",
      "66 (1.1285485609717991, 0.94138839193012402)\n",
      "67 (1.1246995044791179, 0.94805420999941614)\n",
      "68 (1.1245239506597104, 0.95029682957607764)\n",
      "69 (1.1173864260963771, 0.96180713176727295)\n",
      "70 (1.1130206429440042, 0.96728296901868738)\n",
      "71 (1.1074646234512329, 0.97435969528944599)\n",
      "72 (1.1116392156352168, 0.98440828167873884)\n",
      "73 (1.1043307490970777, 0.9885701920675195)\n",
      "74 (1.1059170401614644, 0.98864997988161829)\n",
      "75 (1.1091293739235919, 0.98809874990712043)\n",
      "76 (1.0934065694394319, 1.0077143301134524)\n",
      "77 (1.0928748576537421, 1.0033487444338591)\n",
      "78 (1.1046450148458067, 1.007246548714845)\n",
      "79 (1.1028323339379351, 1.0021378159523011)\n",
      "80 (1.1005484601725704, 1.0051725460135419)\n",
      "81 (1.0959360843119414, 1.0098319027734839)\n",
      "82 (1.0976150657819665, 1.0204707446305648)\n",
      "83 (1.0849669166233229, 1.0259531207706618)\n",
      "84 (1.0864333634791168, 1.0258639475573663)\n",
      "85 (1.0888100401214931, 1.0318965367648913)\n",
      "86 (1.0972434297851894, 1.0288777921510779)\n",
      "87 (1.0880611269370368, 1.0355861026307811)\n",
      "88 (1.0888737569684568, 1.027182708615842)\n",
      "89 (1.0991977137068043, 1.0300792170607525)\n",
      "90 (1.083988266405852, 1.0367559883905493)\n",
      "91 (1.0820493200550909, 1.0490973368934964)\n",
      "92 (1.0886567737745203, 1.044057239656863)\n",
      "93 (1.0856366976447727, 1.0433787812357362)\n",
      "94 (1.0845431436663089, 1.053264059709466)\n",
      "95 (1.085616317520971, 1.0447780692059061)\n",
      "96 (1.0936182239781256, 1.0452802352283312)\n",
      "97 (1.0946472955786664, 1.0533039725345115)\n",
      "98 (1.0863736961198889, 1.0424712616464367)\n",
      "99 (1.0931022840997446, 1.0425160998883454)\n",
      "100 (1.0822759167007778, 1.0619962246521659)\n",
      "101 (1.0924004026081251, 1.0445017130478569)\n",
      "102 (1.0889965181765349, 1.0494524458180303)\n",
      "103 (1.0878925898800726, 1.0601960208105004)\n",
      "104 (1.0923226480898649, 1.0554197586101035)\n",
      "105 (1.0795898655186529, 1.0619218587875365)\n",
      "106 (1.0880165680595066, 1.0662745615710383)\n",
      "107 (1.08158983717794, 1.0582538692847543)\n",
      "108 (1.0933125335237255, 1.0540366691091787)\n",
      "109 (1.0810984834380772, 1.0612267006998477)\n",
      "110 (1.083308660465738, 1.0659396435903465)\n",
      "111 (1.0922857160153596, 1.0592926294907279)\n",
      "112 (1.0834299631740736, 1.068205714225769)\n",
      "113 (1.0790481204571931, 1.0633363982905513)\n",
      "114 (1.0994532839111659, 1.0618501797966335)\n",
      "115 (1.0808369527692381, 1.0715536060540571)\n",
      "116 (1.0907261698142341, 1.0695569644803586)\n",
      "117 (1.0898898549701856, 1.0635280567666758)\n",
      "118 (1.0775508585183518, 1.0656558990478515)\n",
      "119 (1.0828532809796541, 1.0680917066076527)\n",
      "120 (1.0944272564805073, 1.0573546658391537)\n",
      "121 (1.0994597388350444, 1.0599324096804079)\n",
      "122 (1.0833238612050595, 1.0579029083251954)\n",
      "123 (1.093057918548584, 1.0559155987656634)\n",
      "124 (1.0980987849442856, 1.0584892739420351)\n",
      "125 (1.0797851536584937, 1.067490825964057)\n",
      "126 (1.104499105785204, 1.0691997662834498)\n",
      "127 (1.0869002430335335, 1.0554412961006165)\n",
      "128 (1.082266310505245, 1.0587739975556083)\n",
      "129 (1.0944828515467437, 1.0637096809304278)\n",
      "130 (1.0919911161712978, 1.0740552513495736)\n",
      "131 (1.1006181374840114, 1.0687074790830198)\n",
      "132 (1.1055420269136844, 1.0614448106807211)\n",
      "133 (1.0858643365942913, 1.0582544632579969)\n",
      "134 (1.1010037157846533, 1.0613328047420667)\n",
      "135 (1.0843141260354414, 1.0631380490634752)\n",
      "136 (1.0828684951948082, 1.0674977053766666)\n",
      "137 (1.0911453615064206, 1.0533388137817383)\n",
      "138 (1.101715824396714, 1.0603238909140877)\n",
      "139 (1.0921493302220884, 1.0620634488437486)\n",
      "140 (1.0983918065610139, 1.0671820391779361)\n",
      "141 (1.1014487618985382, 1.0681644268657851)\n",
      "142 (1.0858702462652454, 1.0562026220819225)\n",
      "143 (1.1029990108116814, 1.0618750598119653)\n",
      "144 (1.0909447530041569, 1.0529683216758396)\n",
      "145 (1.1244222444036733, 1.0721162314000336)\n",
      "146 (1.0970736482869023, 1.0498763540516729)\n",
      "147 (1.0940958795340165, 1.0602823433668718)\n",
      "148 (1.0947580923204836, 1.0655735259470733)\n",
      "149 (1.0922399500141973, 1.0624245436295219)\n",
      "150 (1.0968767347543136, 1.0592749300210371)\n",
      "151 (1.0979481800742772, 1.0549658510995947)\n",
      "152 (1.0937964734823808, 1.0641959221466728)\n",
      "153 (1.1025822167811186, 1.0675089737643366)\n",
      "154 (1.0921534512353981, 1.0497446661410124)\n",
      "155 (1.1071245685867641, 1.0697445449621781)\n",
      "156 (1.1027637087780497, 1.0734816323155942)\n",
      "157 (1.1014230961384981, 1.0805889482083528)\n",
      "158 (1.0977142567219942, 1.0630795178206072)\n",
      "159 (1.0854606079018634, 1.0735903657000998)\n",
      "160 (1.1181007965751317, 1.0664543991503508)\n",
      "161 (1.1004351211630781, 1.0702304041903952)\n",
      "162 (1.1038450463958409, 1.0641243343767912)\n",
      "163 (1.0902274121408877, 1.0623204236445221)\n",
      "164 (1.090473440937374, 1.0758818590122721)\n",
      "165 (1.0873744264892911, 1.0622744995614757)\n",
      "166 (1.0931511827137159, 1.0634818248126818)\n",
      "167 (1.1438659491746321, 1.0817479232083196)\n",
      "168 (1.0957175731658935, 1.0621172148248423)\n",
      "169 (1.0884431906368421, 1.0597897716190503)\n",
      "170 (1.1040473642556563, 1.0609183119690937)\n",
      "171 (1.0830436592516692, 1.0606860212657763)\n",
      "172 (1.0832457671994749, 1.07373358944188)\n",
      "173 (1.0993376648944357, 1.0695622537447058)\n",
      "174 (1.0934916636218195, 1.0811071758684905)\n",
      "175 (1.0924969616143601, 1.0562890109808549)\n",
      "176 (1.0988444831060327, 1.0848697439483974)\n",
      "177 (1.0878931937010392, 1.0615405404049418)\n",
      "178 (1.0808032891024715, 1.0593567361002383)\n",
      "179 (1.1109555244445801, 1.0814189320025236)\n",
      "180 (1.0934983725133149, 1.0725876507551775)\n",
      "181 (1.088009848801986, 1.0704948300900667)\n",
      "182 (1.093365170126376, 1.0604619176491448)\n",
      "183 (1.0872117778529291, 1.0751653381015944)\n",
      "184 (1.1001784127691518, 1.0776064147119937)\n",
      "185 (1.0969955547996189, 1.079428805993951)\n",
      "186 (1.0971569755802983, 1.0752022763957148)\n",
      "187 (1.0846536029940066, 1.0825046321620111)\n",
      "188 (1.1004284744677337, 1.0807601643645246)\n",
      "189 (1.099483160868935, 1.0819614752479221)\n",
      "190 (1.0945242337558581, 1.0819563269615173)\n",
      "191 (1.0781862699467204, 1.0710381471592447)\n",
      "192 (1.080699430341306, 1.0719538025234057)\n",
      "193 (1.079686543215876, 1.0864965547686039)\n",
      "194 (1.0756645218185756, 1.0827673803205076)\n",
      "195 (1.085701260359391, 1.0545230917308641)\n",
      "196 (1.0849277377128601, 1.0761291156644406)\n",
      "197 (1.077771966872008, 1.0688308124956878)\n",
      "198 (1.1290029085200766, 1.1071248671282892)\n",
      "199 (1.0791631226954252, 1.0808049233063408)\n",
      "200 (1.0844230651855469, 1.0833020630090133)\n",
      "201 (1.1045408938242041, 1.0964778822401295)\n",
      "202 (1.0831859008125637, 1.0848259832548059)\n",
      "203 (1.0771517484084419, 1.0847623446713324)\n",
      "204 (1.078889012336731, 1.0897384752397952)\n",
      "205 (1.0986618430718131, 1.0783246097357377)\n",
      "206 (1.0935321818227353, 1.0884758646073549)\n",
      "207 (1.0827571760053221, 1.0998788237571717)\n",
      "208 (1.0781103927156199, 1.0874165638633397)\n",
      "209 (1.0809282390967658, 1.0898178831390712)\n",
      "210 (1.0855537108753039, 1.0791064257207124)\n",
      "211 (1.0937402922174204, 1.0940179171769515)\n",
      "212 (1.0836133905079053, 1.0913811289745829)\n",
      "213 (1.0971437231354091, 1.0884505235630533)\n",
      "214 (1.0851517573646876, 1.1084770529166512)\n",
      "215 (1.0722814746524976, 1.075094178966854)\n",
      "216 (1.0803877877152483, 1.087859873149706)\n",
      "217 (1.0901770161545794, 1.090301841756572)\n",
      "218 (1.076680382438328, 1.0817292907963629)\n",
      "219 (1.0720723261003908, 1.1070210695266725)\n",
      "220 (1.09796716493109, 1.1114240247270335)\n",
      "221 (1.0769786995390187, 1.0816185904585798)\n",
      "222 (1.0736316546149876, 1.0858277844346087)\n",
      "223 (1.0654935225196507, 1.0892683630404265)\n",
      "224 (1.0872417076774266, 1.1247962378937266)\n",
      "225 (1.0715149646219999, 1.1033577436986177)\n",
      "226 (1.0777521817580513, 1.098313477764959)\n",
      "227 (1.0720502516497736, 1.1023028622502866)\n",
      "228 (1.0798908845238064, 1.1105305148207623)\n",
      "229 (1.0859618233597796, 1.0873072753781858)\n",
      "230 (1.078237163502237, 1.1009573184925576)\n",
      "231 (1.0685710544171541, 1.1003237729487212)\n",
      "232 (1.0702748531880586, 1.0838427559189174)\n",
      "233 (1.0936279364254164, 1.1186339896658193)\n",
      "234 (1.0789416468661763, 1.104107473725858)\n",
      "235 (1.0829502686210302, 1.0935399755187656)\n",
      "236 (1.0843820763670879, 1.1096118429432744)\n",
      "237 (1.0756791068160017, 1.1043383225150731)\n",
      "238 (1.0896834674088851, 1.1053425555643828)\n",
      "239 (1.0797132958536562, 1.1008561823679053)\n",
      "240 (1.0796409238939699, 1.0945076553717903)\n",
      "241 (1.0879441997279291, 1.0973274655964063)\n",
      "242 (1.0782027742137079, 1.0737029288126074)\n",
      "243 (1.0836969116459723, 1.1062331147815869)\n",
      "244 (1.0792640867440597, 1.0976996437363002)\n",
      "245 (1.0704491848530977, 1.0995744041774584)\n",
      "246 (1.077424929452979, 1.0980342512545378)\n",
      "247 (1.0792140126228333, 1.1057461769684502)\n",
      "248 (1.0818266334741011, 1.1042159567708554)\n",
      "249 (1.0789558514304782, 1.0922253774560016)\n",
      "250 (1.0821485436480978, 1.1078594777895057)\n",
      "251 (1.0986064273378124, 1.1071850292060685)\n",
      "252 (1.0764238103576329, 1.0836266517639159)\n",
      "253 (1.0710044829741767, 1.0940350827963456)\n",
      "254 (1.0762397071589593, 1.0976879524148029)\n",
      "255 (1.0963872722957446, 1.1063155734020731)\n",
      "256 (1.0799085741457732, 1.0816329893858536)\n",
      "257 (1.1018067981885826, 1.1150849798451299)\n",
      "258 (1.0709388453027477, 1.0883600924326027)\n",
      "259 (1.0774241509644882, 1.10421797192615)\n",
      "260 (1.0793337713117186, 1.0913003356560418)\n",
      "261 (1.0783874299215235, 1.1238983278689176)\n",
      "262 (1.0877888280412424, 1.1200138677721438)\n",
      "263 (1.0881402238555578, 1.1012280775153118)\n",
      "264 (1.0862244357233461, 1.0869347593058711)\n",
      "265 (1.089232543758724, 1.1024264662162118)\n",
      "266 (1.0780294553093288, 1.0950782516728277)\n",
      "267 (1.0767166982526364, 1.0954291685767796)\n",
      "268 (1.0658336976300116, 1.1005429464837779)\n",
      "269 (1.0879795639411263, 1.1013139657352282)\n",
      "270 (1.0839057797970979, 1.0975371329680732)\n",
      "271 (1.0844539383183356, 1.1087700615758482)\n",
      "272 (1.0684055561604706, 1.1049769515576571)\n",
      "273 (1.0763044331384741, 1.0983816784361133)\n",
      "274 (1.0924348509829978, 1.1001919233280679)\n",
      "275 (1.0666166061940401, 1.0843881586323614)\n",
      "276 (1.0764738601187001, 1.1012485151705536)\n",
      "277 (1.0711921883665998, 1.1201193871705428)\n",
      "278 (1.0726214626561041, 1.1154373168945313)\n",
      "279 (1.0627256580021069, 1.0829286907030189)\n",
      "280 (1.0759893204854882, 1.113433745633001)\n",
      "281 (1.0823959298755812, 1.1091961591140083)\n",
      "282 (1.0770195028056269, 1.0892869581346927)\n",
      "283 (1.0700465134952379, 1.1061340658561043)\n",
      "284 (1.0748619976251022, 1.1179745083269865)\n",
      "285 (1.0672801536062488, 1.1097009451492974)\n",
      "286 (1.0738005746965822, 1.1055828996326613)\n",
      "287 (1.0766839944798015, 1.1073296230772267)\n",
      "288 (1.0754690045895783, 1.1103822407515154)\n",
      "289 (1.0608378384424293, 1.1068059377048327)\n",
      "290 (1.073976299037104, 1.1098686368569084)\n",
      "291 (1.0685776358065397, 1.1057679036389227)\n",
      "292 (1.0650276588357013, 1.1117810529211294)\n",
      "293 (1.0661615537560505, 1.1185731276221897)\n",
      "294 (1.0623828602873762, 1.1236476271048836)\n",
      "295 (1.0631220952324245, 1.1128026568371316)\n",
      "296 (1.0716917442238849, 1.1114328907883686)\n",
      "297 (1.0767520583194234, 1.1192943469337795)\n",
      "298 (1.064658705047939, 1.1129804212114085)\n",
      "299 (1.0580332009688667, 1.1027672145677649)\n",
      "300 (1.0616067368051281, 1.1225489035896632)\n",
      "301 (1.0614260481751483, 1.1288470200870349)\n",
      "302 (1.056058941198432, 1.1326043232627536)\n",
      "303 (1.0605222448058751, 1.1212668600289717)\n",
      "304 (1.0540918422781902, 1.1296033470526985)\n",
      "305 (1.0546653405479762, 1.1317274627478227)\n",
      "306 (1.05226672835972, 1.1332802388979042)\n",
      "307 (1.0495982740236365, 1.1258043957793193)\n",
      "308 (1.0578014270119045, 1.1260743628377501)\n",
      "309 (1.0528204005697499, 1.1232508519421454)\n",
      "310 (1.0581569847853287, 1.1221160738364511)\n",
      "311 (1.0585332600966744, 1.1217583013617474)\n",
      "312 (1.0564358804536902, 1.122343029146609)\n",
      "313 (1.0506887467011161, 1.1187775824380957)\n",
      "314 (1.0546258496201557, 1.1469619999761167)\n",
      "315 (1.0984885360883629, 1.1326617790305096)\n",
      "316 (1.0433142309603485, 1.1427765981010769)\n",
      "317 (1.0654204373774321, 1.1524633936260058)\n",
      "318 (1.0482395348341569, 1.1333403649537459)\n",
      "319 (1.0470010384269384, 1.1271858365639396)\n",
      "320 (1.0396336959755939, 1.1317492085954417)\n",
      "321 (1.0459459413652834, 1.1385792478271153)\n",
      "322 (1.0519470790158147, 1.1399862320526786)\n",
      "323 (1.0572510258011196, 1.1393570656361787)\n",
      "324 (1.044840739602628, 1.1348146008408588)\n",
      "325 (1.0527639425319173, 1.141965171046879)\n",
      "326 (1.0453737901604694, 1.1313047300214354)\n",
      "327 (1.0420962069345556, 1.1686837134153947)\n",
      "328 (1.0390396009320799, 1.1294684461925342)\n",
      "329 (1.0425608178843622, 1.1443643855011982)\n",
      "330 (1.0471658431965372, 1.1331670693729234)\n",
      "331 (1.0355068268983261, 1.1349258516145788)\n",
      "332 (1.0409401701844256, 1.153739849899126)\n",
      "333 (1.038916750057884, 1.1571318895920464)\n",
      "334 (1.0328026978865914, 1.1517153952432715)\n",
      "335 (1.0345994700556216, 1.1339586771052816)\n",
      "336 (1.0356478349022242, 1.1387823161871538)\n",
      "337 (1.0363468942434892, 1.141047185400258)\n",
      "338 (1.0330405162728351, 1.1531915856444317)\n",
      "339 (1.0342830771985261, 1.1591535749642745)\n",
      "340 (1.0273139383481897, 1.1444447895754939)\n",
      "341 (1.0246166125587794, 1.1464537532433219)\n",
      "342 (1.0271252471467722, 1.1525707965311798)\n",
      "343 (1.0310020021770312, 1.1657600319903829)\n",
      "344 (1.036887876883797, 1.1722449841706648)\n",
      "345 (1.0263645379439643, 1.1614459685657335)\n",
      "346 (1.0204919162003889, 1.1578345480172529)\n",
      "347 (1.0334540429322616, 1.1721395067546678)\n",
      "348 (1.0263580695442531, 1.1597896990568741)\n",
      "349 (1.028287635160529, 1.1585095908330834)\n",
      "350 (1.0312383086785026, 1.1790412379347759)\n",
      "351 (1.0375405591467153, 1.1677709263304006)\n",
      "352 (1.0318952487862629, 1.1582336643467779)\n",
      "353 (1.0291378259658814, 1.1559235147807909)\n",
      "354 (1.0150156974792481, 1.1696013709773188)\n",
      "355 (1.0302156038906263, 1.1772369540256002)\n",
      "356 (1.0131931641827459, 1.1670813026635543)\n",
      "357 (1.0288627147674561, 1.1678081714588664)\n",
      "358 (1.031393591735674, 1.1638143010761426)\n",
      "359 (1.0247207014457038, 1.1799902423568394)\n",
      "360 (1.0255438338155332, 1.1767726893010346)\n",
      "361 (1.0168931121411531, 1.1648034095764159)\n",
      "362 (1.0123746939327405, 1.1835304892581442)\n",
      "363 (1.0120658760485441, 1.1709125327027363)\n",
      "364 (1.0117184312447258, 1.183259698100712)\n",
      "365 (1.0184814126595207, 1.1734674935755522)\n",
      "366 (1.0176250841306604, 1.1791203535121419)\n",
      "367 (1.0278602465339328, 1.1738930463790893)\n",
      "368 (1.0108408461446348, 1.191278466452723)\n",
      "369 (1.015065652391185, 1.1885712566583053)\n",
      "370 (1.0153814383175062, 1.1748331303181856)\n",
      "371 (1.0050021508465643, 1.1915775983229928)\n",
      "372 (1.002527846460757, 1.1925031900405885)\n",
      "373 (1.0056702515353326, 1.1836440552835878)\n",
      "374 (1.0160857516786326, 1.1639224643292634)\n",
      "375 (1.0189541339874268, 1.1926031921220863)\n",
      "376 (1.014732669747394, 1.1852628878925158)\n",
      "377 (1.0004124615503394, 1.1688532196957133)\n",
      "378 (0.99688930096833606, 1.1884836632272471)\n",
      "379 (1.0070124610610631, 1.1886068893515545)\n",
      "380 (1.0019825950912806, 1.2141083390816398)\n",
      "381 (1.0022483322931373, 1.1888621522032696)\n",
      "382 (1.0065551141034002, 1.1757550856341485)\n",
      "383 (1.0095080681469129, 1.2161582812019016)\n",
      "384 (1.0024910382602525, 1.1942758482435476)\n",
      "385 (0.99947130783744476, 1.2087061420730922)\n",
      "386 (1.0027282326117806, 1.190985924264659)\n",
      "387 (1.0007191538810729, 1.1921328570531762)\n",
      "388 (1.0020456350368001, 1.1987044267032458)\n",
      "389 (1.0019353306811789, 1.2165064542189887)\n",
      "390 (0.98688011946885479, 1.1908985091292339)\n",
      "391 (1.0104571233624997, 1.2145118910333386)\n",
      "392 (0.99680847033210418, 1.2036457756291266)\n",
      "393 (0.98757092641747513, 1.2058897992838984)\n",
      "394 (0.99415124032808388, 1.1996125682540562)\n",
      "395 (0.99816022904022883, 1.2311710373215052)\n",
      "396 (0.98751724751099301, 1.210432431490525)\n",
      "397 (0.99114588861880093, 1.2063761042511982)\n",
      "398 (0.99109065636344573, 1.2037215828895569)\n",
      "399 (0.99364452258400293, 1.2026037957357323)\n",
      "400 (0.99339977917463884, 1.2180465071097664)\n",
      "401 (1.0019065981325896, 1.2364886112835096)\n",
      "402 (0.98928052238796071, 1.2158684403999993)\n",
      "403 (0.9960503458976746, 1.2197149178256159)\n",
      "404 (0.99228734659112017, 1.2188512568888457)\n",
      "405 (0.99730241816976795, 1.2186866853548133)\n",
      "406 (0.98448995144470874, 1.2118749255719392)\n",
      "407 (0.98383546912151831, 1.2099614609842715)\n",
      "408 (0.98782284311626267, 1.2193438276000645)\n",
      "409 (0.98838030825490542, 1.2159527846004652)\n",
      "410 (0.98566196223963864, 1.2458368534627169)\n",
      "411 (0.98516834559647937, 1.2198979621348174)\n",
      "412 (0.98212570625802742, 1.2272355105565942)\n",
      "413 (0.9947710928709611, 1.2173905693966409)\n",
      "414 (0.9788789489994878, 1.2305930458981058)\n",
      "415 (0.98816393199174302, 1.2115918081739674)\n",
      "416 (0.98580364869988479, 1.2336656192074651)\n",
      "417 (0.99024714386981472, 1.2382556433263032)\n",
      "418 (0.9807121458260909, 1.2283255618551503)\n",
      "419 (0.96887932393861853, 1.2158918147501738)\n",
      "420 (0.98571897175001066, 1.2383272642674654)\n",
      "421 (0.9733897846678029, 1.2279995773149572)\n",
      "422 (0.98846726676692132, 1.2449409484863281)\n",
      "423 (0.98318220480628638, 1.2452604247176129)\n",
      "424 (0.98450899124145508, 1.2359824781832487)\n",
      "425 (0.975953733921051, 1.2163982702338176)\n",
      "426 (0.97490316836730295, 1.2488578081130981)\n",
      "427 (0.98331378542858616, 1.2457415321598881)\n",
      "428 (0.97135990028795993, 1.2493930262068043)\n",
      "429 (0.9744650877040365, 1.254887416570083)\n",
      "430 (0.97534642789674841, 1.2410343885421753)\n",
      "431 (0.96969083806742795, 1.2450923665710119)\n",
      "432 (0.97273606943047564, 1.2418002004208772)\n",
      "433 (0.96399082826531457, 1.2469403681547746)\n",
      "434 (0.96959618381831958, 1.2456323675487353)\n",
      "435 (0.97014619163844895, 1.2281716004661891)\n",
      "436 (0.96981305505918425, 1.2628395360449085)\n",
      "437 (0.96645745712777842, 1.2572846086128899)\n",
      "438 (0.96132570245991578, 1.2337554195652838)\n",
      "439 (0.96194527719331824, 1.2371098502822544)\n",
      "440 (0.97035705058471011, 1.2615821719169618)\n",
      "441 (0.96378851558851164, 1.2389796028966489)\n",
      "442 (0.9789252944614576, 1.2465264662452367)\n",
      "443 (0.96373109713844629, 1.2463390417720961)\n",
      "444 (0.96440560403077502, 1.2521775706954625)\n",
      "445 (0.96883975733881411, 1.2564371347427368)\n",
      "446 (0.96713639134946072, 1.2498031543648762)\n",
      "447 (0.95972156576488332, 1.251833458568739)\n",
      "448 (0.96024649557859998, 1.2428638033244921)\n",
      "449 (0.95348995457524843, 1.2484563749769459)\n",
      "450 (0.95760008770486582, 1.2543177770531695)\n",
      "451 (0.95481168446333509, 1.2484611889590387)\n",
      "452 (0.94951753460842625, 1.2875053198441215)\n",
      "453 (0.95669987668161804, 1.2561484886252361)\n",
      "454 (0.96034746066383692, 1.2788585740586986)\n",
      "455 (0.95631661259609724, 1.2677563371865646)\n",
      "456 (0.94761000716167942, 1.2834296013997948)\n",
      "457 (0.95097091716268789, 1.2720823194669642)\n",
      "458 (0.95669341968453447, 1.2786609789599543)\n",
      "459 (0.95645303881686672, 1.2758742674537327)\n",
      "460 (0.95646172139955599, 1.2619709528010825)\n",
      "461 (0.94576526310132902, 1.2790498733520508)\n",
      "462 (0.94589370696440989, 1.271905907858973)\n",
      "463 (0.94648432109666902, 1.2782192468643188)\n",
      "464 (0.95490319832511572, 1.286858516154082)\n",
      "465 (0.94545441399449892, 1.2726128661114238)\n",
      "466 (0.94413801949957143, 1.2614867687225342)\n",
      "467 (0.95714525502660996, 1.2621244529019231)\n",
      "468 (0.94477774112120916, 1.2796207785606384)\n",
      "469 (0.95459047141282449, 1.2767061249069545)\n",
      "470 (0.9480211672575577, 1.2616589836452319)\n",
      "471 (0.93982599973678593, 1.2896254757176275)\n",
      "472 (0.9430409488470658, 1.2912061965983848)\n",
      "473 (0.95392808655033945, 1.3098617175351019)\n",
      "474 (0.93599950075149541, 1.2677693071572678)\n",
      "475 (0.941600647698278, 1.2909015365268872)\n",
      "476 (0.93767955614172893, 1.2861960706503495)\n",
      "477 (0.9342052273128344, 1.28046163165051)\n",
      "478 (0.93467909875123401, 1.3030612872994465)\n",
      "479 (0.92869796027307927, 1.282718827413476)\n",
      "480 (0.93508614249851396, 1.2959820420845696)\n",
      "481 (0.93490090214687849, 1.2881660632465197)\n",
      "482 (0.93849119207133413, 1.2950395822525025)\n",
      "483 (0.93482867272003833, 1.2972442611404087)\n",
      "484 (0.9391955997632897, 1.2823354057643725)\n",
      "485 (0.93475209733714226, 1.291724665786909)\n",
      "486 (0.93975991425306904, 1.2996574049410612)\n",
      "487 (0.92332864947940996, 1.296057152748108)\n",
      "488 (0.93256369259046468, 1.3051859980044158)\n",
      "489 (0.92304702945377515, 1.2929749063823535)\n",
      "490 (0.92362498148627903, 1.3005575205968773)\n",
      "491 (0.93033546675806456, 1.3172764855882395)\n",
      "492 (0.92276190882143772, 1.297333232216213)\n",
      "493 (0.9231779342112334, 1.298029913591302)\n",
      "494 (0.92410729605218633, 1.3216223794481028)\n",
      "495 (0.91360711584920473, 1.3081747366034466)\n",
      "496 (0.91642054215721458, 1.3187138687009397)\n",
      "497 (0.92071057402569312, 1.3147896709649458)\n",
      "498 (0.9257079139999721, 1.3276651983675749)\n",
      "499 (0.92306890850481782, 1.3125522836394932)\n",
      "500 (0.92381941339244011, 1.3220700466114541)\n"
     ]
    }
   ],
   "source": [
    "# Train the GAN.\n",
    "for _ in range(max_epochs):\n",
    "    loss, duration = gan._single_epoch_train(train_data, batch_size, noise_params)\n",
    "    epoch = int(gan.sess.run(gan.epoch.assign_add(tf.constant(1.0))))\n",
    "    print epoch, loss\n",
    "\n",
    "    if save_model and (epoch % saver_step == 0 or epoch <= 5):\n",
    "        checkpoint_path = osp.join(train_dir, MODEL_SAVER_ID)\n",
    "        gan.saver.save(gan.sess, checkpoint_path, global_step=gan.epoch)\n",
    "\n",
    "    if save_synthetic_samples and epoch in saver_step:\n",
    "        syn_latent_data = gan.generate(n_syn_samples, noise_params)\n",
    "        syn_data = ae.decode(syn_latent_data)\n",
    "        np.savez(osp.join(synthetic_data_out_dir, 'epoch_' + str(epoch)), syn_data)\n",
    "        for k in range(3):\n",
    "            Point_Cloud(syn_data[k]).plot()\n",
    "\n",
    "    train_stats.append((epoch,) + loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if plot_train_curve:\n",
    "    x = range(len(train_stats))\n",
    "    d_loss = [t[1] for t in train_stats]\n",
    "    g_loss = [t[2] for t in train_stats]\n",
    "    plt.plot(x, d_loss, '--')\n",
    "    plt.plot(x, g_loss)\n",
    "    plt.title('Latent GAN training. (%s, %s)' %(class_name, ae_loss))\n",
    "    plt.legend(['Discriminator', 'Generator'], loc=0)\n",
    "    \n",
    "    plt.tick_params(axis='x', which='both', bottom='off', top='off')\n",
    "    plt.tick_params(axis='y', which='both', left='off', right='off')\n",
    "    \n",
    "    plt.xlabel('Epochs.') \n",
    "    plt.ylabel('Loss.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "* Εχεις κρατησει τα txts για του περισσοτερους AEs?\n",
    "* You can manually read them and write them to the appropriate functions and then also \n",
    "add some reading/creation function from raw txt for the configuration.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # TEMP\n",
    "# TO load work with pre-trained SN models.\n",
    "# import sys\n",
    "# sys.path.append(\"../../../../Git_Repos/\")\n",
    "# from research.iclr.helper import load_multiple_version_of_pcs\n",
    "# # in_data = load_multiple_version_of_pcs('uniform_one', syn_id, n_classes=1)\n",
    "# # train_data = in_data['train']\n",
    "# !cat /orions4-zfs/projects/optas/DATA/OUT/iclr/nn_models/ae_chair_mlp_with_split_1pc_usampled_bnorm_on_encoder_only_2048_pts_128_bneck_emd/configuration.txt\n",
    "\n",
    "# ae_configuration = '/orions4-zfs/projects/optas/DATA/OUT/iclr/nn_models/ae_chair_mlp_with_split_1pc_usampled_bnorm_on_encoder_only_2048_pts_128_bneck_emd/configuration.txt\n",
    "\n",
    "ae_conf = Conf.load(ae_configuration)\n",
    "\n",
    "# saved_epochs = read_saved_epochs(ae_conf.train_dir)\n",
    "# _, best_epoch = find_best_validation_epoch_from_train_stats(osp.join(ae_train_dir, 'train_stats.txt'))\n",
    "# if best_epoch % ae_conf.saver_step != 0: # Model was not saved at that epoch.\n",
    "#     best_epoch += best_epoch % ae_conf.saver_step\n",
    "# ae_conf.encoder_args['verbose'] = False\n",
    "# ae_conf.decoder_args['verbose'] = False\n",
    "# reset_tf_graph()\n",
    "# ae = PointNetAutoEncoder(ae_conf.experiment_name, ae_conf)    \n",
    "# ae.restore_model(ae_conf.train_dir, best_epoch, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow1",
   "language": "python",
   "name": "tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
