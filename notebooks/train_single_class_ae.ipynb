{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Execute this cell, only if you didn't add latent_3d_points to your $PYTHONPATH\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from src import *\n",
    "from external import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from src.ae_templates import mlp_architecture_ala_iclr_18, default_train_params\n",
    "\n",
    "from src.autoencoder import Configuration as Conf\n",
    "\n",
    "from src.point_net_ae import PointNetAutoEncoder\n",
    "\n",
    "from src.in_out import snc_category_to_synth_id, Poi\n",
    "\n",
    "from external.general_tools.in_out.basics import create_dir\n",
    "\n",
    "from external.general_tools.notebook.tf import reset_tf_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import os.path as osp\n",
    "\n",
    "# from latent_3d_points.src.ae_templates import mlp_architecture_ala_iclr_18, default_train_params\n",
    "\n",
    "# from latent_3d_points.src.autoencoder import Configuration as Conf\n",
    "# from latent_3d_points.src.point_net_ae import PointNetAutoEncoder\n",
    "# from latent_3d_points.src.in_out import snc_category_to_synth_id\n",
    "\n",
    "# from latent_3d_points.external.general_tools.in_out.basics import create_dir\n",
    "# from latent_3d_points.external.general_tools.notebook.tf import reset_tf_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tf_lab.point_clouds.in_out import load_point_clouds_from_filenames, PointCloudDataSet\n",
    "\n",
    "# from tf_lab.in_out.basics import Data_Splitter\n",
    "# from tf_lab.data_sets.shape_net import pc_loader as snc_loader\n",
    "# from tf_lab.iclr.helper import load_multiple_version_of_pcs, find_best_validation_epoch_from_train_stats\n",
    "\n",
    "# TODO : DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Basic Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me the class name (e.g. \"chair\"): chair\n"
     ]
    }
   ],
   "source": [
    "top_data_dir = '../data/'\n",
    "experiment_name = 'single_class_ae'\n",
    "n_pc_points = 2048\n",
    "class_name = raw_input('Give me the class name (e.g. \"chair\"): ').lower()\n",
    "bneck_size = 128\n",
    "ae_loss = 'emd'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Default Training Parameters\n",
    "\n",
    "{'batch_size': 50,\n",
    " 'denoising': False,                   # By default our AE is not denoising.\n",
    " 'learning_rate': 0.0005,\n",
    " 'loss_display_step': 1,\n",
    " 'saver_step': 10,\n",
    " 'training_epochs': 500,\n",
    " 'z_rotate': False}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dir = create_dir(osp.join(top_data_dir, experiment_name))\n",
    "train_params = default_train_params()\n",
    "encoder, decoder, enc_args, dec_args = mlp_architecture_ala_iclr_18(n_pc_points, bneck_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conf = Conf(n_input = [n_pc_points, 3],\n",
    "            loss = ae_loss,\n",
    "            training_epochs = train_params['training_epochs'],\n",
    "            batch_size = train_params['batch_size'],\n",
    "            denoising = train_params['denoising'],\n",
    "            learning_rate = train_params['learning_rate'],\n",
    "            train_dir = train_dir,\n",
    "            loss_display_step = train_params['loss_display_step'],\n",
    "            saver_step = train_params['saver_step'],\n",
    "            z_rotate = train_params['z_rotate'],\n",
    "            encoder = encoder,\n",
    "            decoder = decoder,\n",
    "            encoder_args = enc_args,\n",
    "            decoder_args = dec_args\n",
    "           )\n",
    "conf.experiment_name = experiment_name\n",
    "conf.held_out_step = 5\n",
    "conf.save(osp.join(train_dir, 'configuration'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build AE Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Encoder\n",
      "encoder_conv_layer_0 conv params =  256 bnorm params =  128\n",
      "Tensor(\"single_class_ae_2/Relu:0\", shape=(?, 2048, 64), dtype=float32)\n",
      "output size: 131072 \n",
      "\n",
      "encoder_conv_layer_1 conv params =  8320 bnorm params =  256\n",
      "Tensor(\"single_class_ae_2/Relu_1:0\", shape=(?, 2048, 128), dtype=float32)\n",
      "output size: 262144 \n",
      "\n",
      "encoder_conv_layer_2 conv params =  16512 bnorm params =  256\n",
      "Tensor(\"single_class_ae_2/Relu_2:0\", shape=(?, 2048, 128), dtype=float32)\n",
      "output size: 262144 \n",
      "\n",
      "encoder_conv_layer_3 conv params =  33024 bnorm params =  512\n",
      "Tensor(\"single_class_ae_2/Relu_3:0\", shape=(?, 2048, 256), dtype=float32)\n",
      "output size: 524288 \n",
      "\n",
      "encoder_conv_layer_4 conv params =  32896 bnorm params =  256\n",
      "Tensor(\"single_class_ae_2/Relu_4:0\", shape=(?, 2048, 128), dtype=float32)\n",
      "output size: 262144 \n",
      "\n",
      "Tensor(\"single_class_ae_2/Max:0\", shape=(?, 128), dtype=float32)\n",
      "Building Decoder\n",
      "decoder_fc_0 FC params =  33024 Tensor(\"single_class_ae_2/Relu_5:0\", shape=(?, 256), dtype=float32)\n",
      "output size: 256 \n",
      "\n",
      "decoder_fc_1 FC params =  65792 Tensor(\"single_class_ae_2/Relu_6:0\", shape=(?, 256), dtype=float32)\n",
      "output size: 256 \n",
      "\n",
      "decoder_fc_2 FC params =  1579008 Tensor(\"single_class_ae_2/decoder_fc_2/BiasAdd:0\", shape=(?, 6144), dtype=float32)\n",
      "output size: 6144 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "reset_tf_graph()\n",
    "ae = PointNetAutoEncoder(conf.experiment_name, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start training\n",
    "buf_size = 1 # flush each line\n",
    "fout = open(osp.join(conf.train_dir, 'train_stats.txt'), 'a', buf_size)\n",
    "train_stats = ae.train(in_data['train'], conf, log_file=fout, held_out_data=in_data['val'])\n",
    "fout.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow1",
   "language": "python",
   "name": "tf1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
